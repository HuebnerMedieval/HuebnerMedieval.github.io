---
layout: post
title:      "The Language of Code"
date:       2021-02-06 20:50:13 +0000
permalink:  the_language_of_code
---


It has become to say that learning to code is like learning a language. We use code as a means of communicating with a computer, and by fascilitating that communication it is a language. It has rules like language, with grammar and vocabulary unique to each language. Like with human languages, there are language groups, and learning one member of a group can each the process of learning the others.

As someone who has learned many human languages (English, Japanese, Latin, German, and Norwegian) and how several of those languages have changed over time (Middle English, Medieval Latin, and Old Norse), I was curious how learning to code would compare with learning a language.

The first thing for non-language learners to know is that there are many approaches to learning a language. The more traditional form is a memorization based education focused on memorizing the rules. This is how language is often taught in middle and high school. This style doesn't work for many people (how many times has someone said "I learned ${language} in high school, but I don't remember any of it?). The other main style is called language immersion, and it is based on being forced to use the language, understanding others and being understood yourself, figuring out the rules as you need them.

With both code and human language, immersion is definitely the way to go. I started my coding journey making cheat sheets and memorizing syntax as a list of unrelated terms. As anyone who has tried to memorize vocabulary can tell you, it didn't stick. The list got ever longer, and I found myself needing to refer to the cheatsheet constantly. It was as difficult as trying to speak Japanese with your nose buried in a vocab list...workable, but VERY inefficient. I realized that the things I used all the time, I could easily use again. If I didn't remember how to do something, it was because it had a niche use case and I didn't need it (how often do you need subjunctives when asking directions on the street of Berlin?). Just like human language, the more you use code, and the more ways in which you use it, strength your ability to "speak" it.

So the same strategies work learning code and human language. In both cases you are learning vocabulary (the terms themselves) and grammar (how those terms fit together to create meaning). Producing and understanding are two different skills that have to be practiced separately. What else? I mentioned at the start that I have studied language over time. As we all know, technology improved exponentially fast. Human languages do shift, but it happens slowly. The language of Chaucer over 600 years ago is distinct from modern English, but if you read it out loud it makes almost perfect sense. Programming languages change MUCH faster. The Flatiron curriculum is proof of that. It was written a mere 5 years ago (as of my time in the course in 2020) but almost every section includes a passage about how everything we were just taught is not obsolete and there is a new way of doing it. If you learn German, you can understand German back half a millenium at least and be understood by basically all German speakers in your lifetime. Learn JavaScript, and you will have to relearn it every couple years to continue writing modern JavaScript.

The speed at which programming languages evolve is what really sets them apart from human languages. Human languages change because we get lazy. A case gets hard in a declined language? Shift it's function to another case and drop the old one (Norwegian and German have both done this). Letters have lots of pronounciations? Break them into separate letters ("i", "j", and "y" were the same letter in until the 1300's and 1400's). This happens slowly. With code, authors are constantly changing, streamlining, and optimizing. Code isn't something you learn once then use, it is a committment to maintain a skill.

This can be frustrating as a student. It is not like learning history, where you learn the canon then you go on to use it. Even spoken languages have a commonly agreed upon curriculum that once you know, you can use the language. Programming is not like that. When you start learning, it becomes clear that you will not "graduate", you will not "finish the course" and know how to code. You are being shown the current state of the language and in exchange implicitly promising to keep up as it continues to expand.
